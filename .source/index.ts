// @ts-nocheck -- skip type checking
import { _runtimeAsync, buildConfig } from "fumadocs-mdx/runtime/async"
const [err, _sourceConfig] = buildConfig(_source)
if (!_sourceConfig) throw new Error(err)
import { _runtime } from "fumadocs-mdx"
import * as _source from "../source.config"
export const blog = _runtimeAsync.doc<typeof _source.blog>([{"info":{"path":"nextjs-x-devto.mdx","absolutePath":"/home/mpaucot/workspace/blog/content/blog/nextjs-x-devto.mdx"},"lastModified":"2025-04-03T23:53:58.000Z","data":{"title":"Build a Blog using Next.JS and DEV.to","description":"Learn how to build your personal blog by using DEV.to as your CMS.","type":"article","date":"2023-03-17T00:00:00.000Z"},"content":"\nIn this article you will learn how to build a Next.JS blog by fetching your Posts directly from DEV.to.\n\n---\n\nI received an incredible feedback from my Post [Use Notion as a database for your Next.JS Blog](https://dev.to/martinp/use-notion-as-a-database-for-your-nextjs-blog-195p) thanks from all of you 🙌\n\n_I even saw the Post on the front page of daily.dev 😶_\n\nToday I wanted to share with you how I built my [Personal Blog](https://martin-paucot.fr) under an hour by using the [DEV.to](https://dev.to/) API.\n\n**Let's get started 🔥**\n\n---\n\n## 1. Create a new Next.JS App\n\nStart by using the [create-next-app](https://nextjs.org/docs/pages/api-reference/create-next-app) utility using your favorite package manager.\n\n```package-install\nnpx create-next-app@latest\nyarn create next\npnpm create next\n```\n\n> Check ✅ for everything! We want linting, typings and obviously the App Router! I also highly recommend to use the `src` folder.\n\n## 2. Install dependencies\n\nYou will need 9 dependencies:\n\n- **[remark](https://github.com/remarkjs/remark):** We will use it to parse our Posts Markdown\n- **[remark-html](https://github.com/remarkjs/remark-html):** A Remark plugin to transform our Markdown into HTML\n- **[rehype](https://github.com/rehypejs/rehype):** A library to process and extend HTML\n- **[rehype-highlight](https://github.com/rehypejs/rehype-highlight):** A Rehype plugin to plug [highlight.js](https://highlightjs.org/) to highlight our code\n- **[rehype-slug](https://github.com/rehypejs/rehype-slug):** A Rehype plugin that adds ids to our Post titles (anchors)\n- **[@jsdevtools/rehype-toc](https://github.com/JS-DevTools/rehype-toc):** A Rehype plugin that generates a table of content based on our Post titles\n- **[rehype-stringify](https://github.com/rehypejs/rehype):** A Rehype plugin that transform our Rehype output into a String\n- **[remark-rehype](https://github.com/remarkjs/remark-rehype):** A Remark plugin to use Remark and Rehype in symbiose\n- **[unified](https://unifiedjs.com/):** The library to make easy to use all thoses plugins together\n\n```package-install\nnpm install remark remark-html rehype rehype-highlight rehype-slug @jsdevtools/rehype-toc rehype-stringify remark-rehype unified\n```\n\n## 3. Fetch from DEV.to\n\n[DEV.to](https://dev.to/) provide a wonderful Public API that does not require any authentication you can find the official documentation [here](https://developers.forem.com/api/v1).\n\nIn our case we will need two things:\n\n- Fetching our Posts `/api/articles?username=<username>`\n- Fetching a specific Post `/api/articles/<username>/<post-slug>`\n\n### Add environment variables\n\nIt is a good practice to avoid hardcoding values, in case you want to change your username or open-source your blog.\n\nAdd your DEV.to username in `.env.local` to avoid hardcoding it:\n\n```dotenv\nDEVTO_USERNAME=\"martinp\"\n```\n\n### Add typings\n\nLet's add some typings to type the response of the DEV.to API in `src/lib/devto/types.ts`:\n\n```ts\n// src/lib/devto/types.ts\n\nexport type User = {\n  user_id: number;\n  name: string;\n  username: string;\n  twitter_username: string | null;\n  github_username: string | null;\n  website_url: string | null;\n  profile_image: string;\n  profile_image_90: string;\n};\n\nexport type Post = {\n  type_of: string;\n  id: number;\n  title: string;\n  description: string;\n  readable_publish_date: string;\n  slug: string;\n  path: string;\n  url: string;\n  comments_count: number;\n  collection_id: number | null;\n  published_timestamp: string;\n  positive_reactions_count: number;\n  cover_image: string | null;\n  social_image: string;\n  canonical_url: string;\n  created_at: string;\n  edited_at: string;\n  crossposted_at: string | null;\n  published_at: string;\n  last_comment_at: string;\n  reading_time_minutes: number;\n  tag_list: string[];\n  tags: string;\n  user: User;\n};\n\nexport type PostDetails = Post & {\n  body_html: string;\n  body_markdown: string;\n  tags: string[];\n};\n```\n\n> I manually made thoses types and they maybe does not exactly match the actual API, feel free to update them.\n\n### Create the fetching functions\n\nNext create a new file `src/lib/devto/fetch.ts`, it will contains the functions that will fetch the API. It is a good practice to separate them from your App to make them easily reusable.\n\n```ts title=\"src/lib/devto/fetch.ts\"\nimport { notFound } from \"next/navigation\";\nimport { Post, PostDetails } from \"./types\";\n\nexport async function fetchPosts(): Promise<Post[]> {\n  const res = await fetch(\n    `https://dev.to/api/articles?username=${process.env.DEVTO_USERNAME}`,\n    {\n      next: { revalidate: 3 * 60 * 60 },\n    },\n  );\n\n  if (!res.ok) notFound();\n  return res.json();\n}\n\nexport async function fetchPost(slug: string): Promise<PostDetails> {\n  const res = await fetch(\n    `https://dev.to/api/articles/${process.env.DEVTO_USERNAME}/${slug}`,\n    {\n      next: { revalidate: 3 * 60 * 60 },\n    },\n  );\n\n  if (!res.ok) notFound();\n  return res.json();\n}\n```\n\nNotice that we add the parameter `revalidate: 3 * 60 * 60`. By default the `fetch` function extended by Next.JS will cache everything. It will make your Blog blazingly fast but we also want to keep our Blog up to date. With this parameter we tell Next.JS to revalidate the cache every 3 hours.\n\n> `notFound()` acts like a return and will show the `not-found.tsx` page. [More information here](https://nextjs.org/docs/app/api-reference/functions/not-found).\n\n## 4. Create the render function\n\nNow let's create a function to render the content of your Posts by using Remark, Rehype and all the plugins:\n\n```ts\n// src/lib/markdown.ts\n\nimport toc from \"@jsdevtools/rehype-toc\";\nimport rehypeHighlight from \"rehype-highlight\";\nimport rehypeSlug from \"rehype-slug\";\nimport rehypeStringify from \"rehype-stringify\";\nimport remarkRehype from \"remark-rehype\";\nimport remarkParse from \"remark-parse\";\nimport { unified } from \"unified\";\n\nexport function renderMarkdown(markdown: string): Promise<string> {\n  return unified()\n    .use(remarkParse)\n    .use(remarkRehype)\n    .use(rehypeHighlight, { ignoreMissing: true })\n    .use(rehypeSlug)\n    .use(rehypeStringify)\n    .use(toc, {\n      headings: [\"h1\", \"h2\", \"h3\"],\n    })\n    .process(markdown)\n    .then((res) => res.toString());\n}\n```\n\n## 5. Create the pages\n\nNow that you have everything in place to fetch your posts, it is time to create the pages!\n\n### The Posts page\n\nIt can't be simpler, simply use your `fetchPosts` function and show them:\n\n```tsx\n// src/app/blog/page.tsx\n\nimport { fetchPosts } from \"@/lib/devto/fetch\";\n\nexport default async function Page() {\n  const posts = await fetchPosts();\n\n  return (\n    <div className=\"grid grid-cols-1 md:grid-cols-2 gap-4 py-8\">\n      {posts.map((post) => (\n        <Link href={`/blog/${post.slug}`}>{post.title}</Link>\n      ))}\n    </div>\n  );\n}\n```\n\n### The Post page\n\nCreate a new page with a dynamic segment for our slug `src/app/blog/[slug]/page.tsx`.\n\nUse the parameters to fetch the post and use the `renderMarkdown` function to transform your Markdown into HTML.\n\nYou can also add `generateMetadata` to set the title and the description using the data of your Post.\n\n```tsx\n// src/app/blog/[slug]/page.tsx\n\nimport \"highlight.js/styles/github-dark.css\"; // Import your favorite highlight.js theme\n\nimport { fetchPost, fetchPosts } from \"@/lib/devto/fetch\";\nimport { renderMarkdown } from \"@/lib/markdown\";\n\nexport async function generateMetadata({\n  params,\n}: {\n  params: { slug: string };\n}) {\n  const { title, description } = await fetchPost(params.slug);\n\n  return {\n    title,\n    description,\n  };\n}\n\nexport default async function Page({ params }: { params: { slug: string } }) {\n  const { body_markdown } = await fetchPost(params.slug);\n\n  const content = await renderMarkdown(body_markdown);\n\n  return (\n    <>\n      <article>\n        <div dangerouslySetInnerHTML={{ __html: content }} />\n      </article>\n    </>\n  );\n}\n```\n\nNotice that you are calling twice the `fetchPost` method, so are you fetching twice? No! It uses the cache, you can verify it when running the `dev` server, you should see `cache: HIT`.\n\n**And you know what is reaaaally cool?**\nNavigate to the list of your posts and hover the links, you should see in your console your `/blog/[slug]` pages pre-rendering to predict the user navigation 🔥\n\n## 6. Going further\n\n- Use [next-sitemap](https://www.npmjs.com/package/next-sitemap) to generate your Sitemap\n- Add [@vercel/analytics](https://vercel.com/docs/concepts/analytics/quickstart) to gather analytics from your blog\n- Use [@tailwindcss/typography](https://tailwindcss.com/docs/typography-plugin) to easily style the content of your posts\n\n---\n\nI hope that this post motivated you to build an incredible blog! Share your work in the comment section! 💬\n\nOh and if you want more content like this, follow me:\n\n- [DEV.to](https://dev.to/martinp)\n- [Twitter](https://twitter.com/PaucotMartin)\n"}, {"info":{"path":"nextjs-x-notion.mdx","absolutePath":"/home/mpaucot/workspace/blog/content/blog/nextjs-x-notion.mdx"},"lastModified":"2025-04-03T23:53:58.000Z","data":{"title":"Use Notion as a database for your Next.JS Blog","description":"Learn how to build your personal blog by using Notion as your CMS.","type":"article","date":"2023-03-13T00:00:00.000Z"},"content":"\nNotion is an extremely powerful tool to manage your content by creating a database you can even add properties to pages: publication date, tags, etc.\n\nIn this Post you will learn how to fetch pages from the Notion API and render their content to create a wonderful Next.JS Blog entirely managed with Notion.\n\n## Create a Notion Database\n\nA Notion Database is a list of pages with defined properties, it provides features to easily manage your content with different type of views (table, calendar, etc).\n\nFor the purpose of this guide we will add the following properties:\n\n- **Title:** The title of the post\n- **Date:** The date of the post\n- **Status:** The status of the post (Not started, Draft, Published)\n- **Created time:** The creation date of the post\n\nDo not forget to create your posts and write some content in them!\n\n> Feel free to add your own properties and tweak them to your needs. You could for example add a publication date to automaticaly publish at a certain date.\n\n![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7jw1gfpzz3hysrzk264c.png)\n\n### Find the database ID\n\nLater in this guide you will need the ID of your database.\n\n## Get a Notion Token\n\n### Create an Integration\n\nIn order to interact with the Notion API you will need an **Internal Integration Token aka. Notion Token**.\n\nHead over the [following link](https://www.notion.so/my-integrations) to create a new Notion Integration. In our case we will only read data, you should only add the Read capacity.\n\nWhen your integration is created you will have an Internal Integration Token. Save it and keep it safe, it will be the \"Notion token\" that you will use to authenticate to the API.\n\n![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ehe3we54ys3uzso2zhgb.gif)\n\n### Authorize the integration to your databases\n\nYou must explicitly give the permission to your integration to query your databases.\n\nClick on the `•••` in the top right corner of your database, then on **Add connection** and select your Integration.\n\n> To avoid giving access to each of your databases, you can add the integration to a parent page.\n\n## Setup the project\n\nLet's install the required dependencies. We are going to use four libraries:\n\n- [@notionhq/client](https://www.npmjs.com/package/@notionhq/client) The official Notion Javascript SDK\n- [@notion-render/client](https://www.npmjs.com/package/@notion-render/client) A library to transform Notion Blocks (page content) into HTML\n- [@notion-render/hljs-plugin](https://www.npmjs.com/package/@notion-render/hljs-plugin) A plugin to highlight your code blocks\n- [@notion-render/bookmark-plugin](https://www.npmjs.com/package/@notion-render/bookmark-plugin) A plugin to fetch website metadata to render bookmarks\n\n```package-install\nyarn add @notionhq/client @notion-render/client @notion-render/hljs-plugin @notion-render/bookmark-plugin\n```\n\nThen store your Internal Integration Token and the database Id into your `.env.local` file so you can access it later.\n\n```dotenv\nNOTION_TOKEN=\"secret_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\nNOTION_DATABASE_ID=\"xxxxxxxxxxxxxxxxxxxxxxx\"\n```\n\n## Create the Post Page\n\n### Create the Notion Client\n\nCreate a new file `lib/notion.ts` we will add inside the functions we need to fetch our posts.\n\n```tsx\nimport \"server-only\";\n\nimport { Client } from \"@notionhq/client\";\nimport React from \"react\";\nimport {\n  BlockObjectResponse,\n  PageObjectResponse,\n} from \"@notionhq/client/build/src/api-endpoints\";\n\nexport const notion = new Client({\n  auth: process.env.NOTION_TOKEN,\n});\n\nexport const fetchPages = React.cache(() => {\n  return notion.databases.query({\n    database_id: process.env.NOTION_DATABASE_ID!,\n    filter: {\n      property: \"Status\",\n      select: {\n        equals: \"Published\",\n      },\n    },\n  });\n});\n\nexport const fetchPageBySlug = React.cache((slug: string) => {\n  return notion.databases\n    .query({\n      database_id: process.env.NOTION_DATABASE_ID!,\n      filter: {\n        property: \"Slug\",\n        rich_text: {\n          equals: slug,\n        },\n      },\n    })\n    .then((res) => res.results[0] as PageObjectResponse | undefined);\n});\n\nexport const fetchPageBlocks = React.cache((pageId: string) => {\n  return notion.blocks.children\n    .list({ block_id: pageId })\n    .then((res) => res.results as BlockObjectResponse[]);\n});\n```\n\nYou can notice two things:\n\n- `import 'server-only';`\n\nThis line make sure that the file never get imported by the client to avoid leaking your Notion Token.\n\n- `React.cache`\n\nNext.JS provide an extremely good caching system with the `fetch()` function but we can not benefit from it as we are using the Notion JS SDK.\n\nInstead we can use `React.cache`, a powerful method that will returns the same result if we call our function with the same parameters.\n\n### Create the page\n\nCreate a page with a dynamic segment `[slug]`. Inside we will fetch our pages so it must be a Server Component:\n\n```tsx [title=\"app/blog/[slug]/page.tsx\"]\nimport { fetchPageBlocks, fetchPageBySlug } from \"@/lib/notion\";\nimport { notFound } from \"next/navigation\";\n\nexport default async function Page({ params }: { params: { slug: string } }) {\n  const post = await fetchPageBySlug(params.slug);\n  if (!post) notFound();\n\n  const content = await fetchPageBlocks(post.id);\n\n  return <></>;\n}\n```\n\n### Render the page content\n\n```tsx\nimport { fetchPageBlocks, fetchPageBySlug, notion } from \"@/lib/notion\";\nimport bookmarkPlugin from \"@notion-render/bookmark-plugin\";\nimport { NotionRenderer } from \"@notion-render/client\";\nimport hljsPlugin from \"@notion-render/hljs-plugin\";\nimport { notFound } from \"next/navigation\";\n\nexport default async function Page({ params }: { params: { slug: string } }) {\n  const post = await fetchPageBySlug(params.slug);\n  if (!post) notFound();\n\n  const blocks = await fetchPageBlocks(post.id);\n\n  const renderer = new NotionRenderer({\n    client: notion,\n  });\n\n  renderer.use(hljsPlugin());\n  renderer.use(bookmarkPlugin());\n\n  const html = await renderer.render(...blocks);\n\n  return <div dangerouslySetInnerHTML={{ __html: html }}></div>;\n}\n```\n\n## Next steps\n\n- Import your favorite [highlight.js](https://highlightjs.org/) theme\n- Import the Notion theme from `@notion-render/client/sass/theme.scss`\n- Create a theme with your own branding\n- Use [`generateStaticParams`](https://nextjs.org/docs/app/api-reference/functions/generate-static-params) to generate pages at build time\n- Use [`draftMode`](https://nextjs.org/docs/app/building-your-application/configuring/draft-mode) to preview your Post not published yet\n"}, {"info":{"path":"stop-nesting-your-code.mdx","absolutePath":"/home/mpaucot/workspace/blog/content/blog/stop-nesting-your-code.mdx"},"lastModified":"2025-04-03T23:53:58.000Z","data":{"title":"Stop Nesting Your Code","type":"article","date":"2023-03-12T00:00:00.000Z"},"content":"\nI am what we call a **Never Nester** and in this Post I will show you why and how to become one of us.\n\n## What is Nesting?\n\nWhen using conditions, for-loops or while-loops we add one layer of indentation of the wrapped code. Some languages requires it and some no. But at the end it is **essential** for readability.\n\nIn the following code that I purposely made unappealing for this Post, we can see that we have up to three layers:\n\n- The condition matching the email\n- The condition checking for an existing user\n- The try catch for the creation of our user\n\n```typescript\nasync function registerUser(email: string, plainPassword: string) {\n  if (email.match(/^[\\w-\\.]+@([\\w-]+\\.)+[\\w-]{2,4}$/)) {\n    let user = await findUserByEmail(email);\n    if (!user) {\n      const rounds = process.env.BCRYPT_ROUNDS;\n      if (rounds) {\n        try {\n          const password = await bcrypt.hash(plainPassword, 10);\n          user = await createUser(email, password);\n          return user;\n        } catch (e) {\n          throw new Error(\"Error while creating user\");\n        }\n      } else {\n        throw new Error(\"Environment variable BCRYPT_ROUNDS not found\");\n      }\n    } else {\n      throw new Error(\"User already exists\");\n    }\n  } else {\n    throw new Error(\"Not a valid email\");\n  }\n}\n```\n\n## The problem of Nesting\n\n**The more layers you have, the harder it is to read.**\n\nWhen reading nested code we have to keep in mind in what context we are, in what conditions or loop we are.\n\nAnd when using `if {} else {}` we have to go back and forth to understand what happens if the condition does not match while keeping the context when reading.\n\n## How to Denest\n\n### Invert your code\n\nWe usually write our code the way we think it:\n\n- \"I want to be sure that my email is exact\"\n- \"I want to be sure that I do not have a user with the same email\"\n\nBut with this process we handle the negative case at the end of our code in the `else`. Instead we should imagine our code this way:\n\n- \"I do not want a user with a wrong email\"\n- \"I do not want to have a user with the same email\"\n\nThe goal of this process is to `return` or `throw` as early as possible:\n\n```typescript\nasync function registerUser(email: string, plainPassword: string) {\n  if (!email.match(/^[\\w-\\.]+@([\\w-]+\\.)+[\\w-]{2,4}$/)) {\n    throw new Error(\"Not a valid email\");\n  }\n\n  let user = await findUserByEmail(email);\n  if (user) {\n    throw new Error(\"User already exists\");\n  }\n\n  const rounds = process.env.BCRYPT_ROUNDS;\n  if (!rounds) {\n    throw new Error(\"Environment variable BCRYPT_ROUNDS not found\");\n  }\n\n  try {\n    const password = await bcrypt.hash(plainPassword, 10);\n    user = await createUser(email, password);\n    return user;\n  } catch (e) {\n    throw new Error(\"Error while creating user\");\n  }\n}\n```\n\nWe now have only one layer by simply inverting our conditions.\n\n### Extract your code\n\nBy extracting we do not only improve the readability of our code, but also its reusability and abstraction.\n\nTo find what we should extract we have to ask ourself what are the minimum dependencies required by the code I'm writing.\n\nThe method is to replace most of `the` by `a` and removing most of the subjects we can.\n\nFor example:\n\n- \"I want to hash the password of the user that I am registering using the environment variable `BCRYPT_ROUNDS` that can be undefined\"\n\nBecome:\n\n- \"I want to hash a password using the environment variable `BCRYPT_ROUNDS` that can be undefined\"\n\n> We know for sure that we will always hash the password everytime a user is created, we can also move this part in the `createUser` function to avoid future duplicated code.\n\n```typescript\nasync function createUser(email, password): Promise<User> {\n  return db.users.insert({\n    email,\n    password: hashPassword(password),\n  });\n}\n\nasync function hashPassword(password: string) {\n  const rounds = process.env.BCRYPT_ROUNDS;\n  if (!rounds) throw new Error(\"Environment variable BCRYPT_ROUNDS not found\");\n  return bcrypt.hash(password, 10);\n}\n\nasync function registerUser(email: string, plainPassword: string) {\n  if (!email.match(/^[\\w-\\.]+@([\\w-]+\\.)+[\\w-]{2,4}$/)) {\n    throw new Error(\"Not a valid email\");\n  }\n\n  let user = await findUserByEmail(email);\n  if (user) {\n    throw new Error(\"User already exists\");\n  }\n\n  return createUser(email, plainPassword);\n}\n```\n"}, {"info":{"path":"stunning-3d-pure-css.mdx","absolutePath":"/home/mpaucot/workspace/blog/content/blog/stunning-3d-pure-css.mdx"},"lastModified":"2025-04-03T23:53:58.000Z","data":{"title":"How to do stunning 3D with pure HTML/CSS","description":"Learn how to create 3D animations by using only HTML and CSS.","type":"article","date":"2023-09-08T00:00:00.000Z"},"content":"\nHTML and CSS may be the bedrock of 2D web design, but hidden within their virtual toolbox are the secrets to creating breathtaking 3D perspectives. Imagine crafting interactive interfaces that transcend flatland into a world where the X, Y, and Z axes dance together. In this blog post, we'll unveil the magic of HTML and CSS's 3D capabilities, guiding you through the essential properties and techniques to create stunning 3D visuals.\n\n**Like this one!**\n\n---\n\n## Introduction\n\n### Harnessing Perspective in HTML\n\nAlthough HTML and CSS are primarily designed for constructing 2D layouts, there are still 3 axes (X, Y & Z) enabling the creation of perspective through specific CSS properties.\n\n#### The `perspective` property\n\nThe [perspective](https://developer.mozilla.org/en-US/docs/Web/CSS/perspective) property alters the user's perspective by adjusting the position of the [vanishing Point](https://en.wikipedia.org/wiki/Vanishing_point) along the Z-axis.\n\nFor example, with the following code, utilizing the following code snippet will establish a distance of 800px between the user and the plane (Z-axis).\n\n```css\n.perspective {\n  position: relative;\n  perspective: 800px;\n}\n```\n\n```html\n<div class=\"perspective\"></div>\n```\n\n#### The `perspective-origin` property\n\nThe [perspective-origin](https://developer.mozilla.org/fr/docs/Web/CSS/perspective-origin) property determines the user's position along the X and Y axes.\n\nTo view an object from above, you can employ the following code:\n\n```css\n.perspective {\n  position: relative;\n  perspective: 800px;\n  perspective-origin: 50% -200px;\n}\n```\n\n> In this example, we are centered on the X-axis (50%) and positioned -200px on the Y-axis.\n\n---\n\nNow that you have grasped the essentials of 3D in HTML and CSS, let's embark on creating our own 3D cube!\n\n### 1. Building the Foundation\n\nFor our HTML structure, we will construct a perspective plane and add a div element for each face of our cube.\n\n```html\n<div class=\"perspective\">\n  <div class=\"box\">\n    <div class=\"face top\"></div>\n    <div class=\"face bottom\"></div>\n    <div class=\"face back\"></div>\n    <div class=\"face front\"></div>\n    <div class=\"face left\"></div>\n    <div class=\"face right\"></div>\n  </div>\n</div>\n```\n\nNow, let's imbue our perspective plane with a specific perspective. In our case, we desire an overhead view of our cube.\n\n```css\n.perspective {\n  perspective: 800px;\n  perspective-origin: 50% -200px;\n}\n```\n\nThen, we'll assign dimensions to our box and apply styling to our individual faces. To keep the 3D rendering within the perspective plane in our div, we incorporate `transform-style: preserve-3d`.\n\n```css\n.box {\n  width: var(--size);\n  aspect-ratio: 1;\n\n  position: relative;\n  transform-style: preserve-3d;\n}\n\n.face {\n  position: absolute;\n  width: var(--size);\n  aspect-ratio: 1;\n\n  background-color: hsl(39, 100%, 66%);\n\n  transform-style: preserve-3d;\n}\n```\n\nAt this point, you should see all the faces superimposed at the same location, forming a square.\n\n![Picture of the result](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/59qkukrwk1yar0wjzjxj.png)\n\n### 2. Creating the Pattern\n\nNow, let's fabricate the 2D pattern of our cube, which we will then fold like a piece of paper. Additionally, we will incorporate a rotation animation for a better 3D visualization.\n\n> Creating a pattern simplifies the process of rotating and positioning elements accurately, preventing confusion with inverted faces.\n\n```css\n.box {\n  animation: rotate 4s linear infinite;\n}\n\n.face.front {\n}\n\n.face.bottom {\n  top: 100%;\n}\n\n.face.top {\n  bottom: 100%;\n}\n\n.face.back {\n  bottom: 200%;\n}\n\n.face.right {\n  left: 100%;\n}\n\n.face.left {\n  right: 100%;\n}\n\n@keyframes rotate {\n  from {\n    transform: rotate(0);\n  }\n  to {\n    transform: rotateY(360deg);\n  }\n}\n```\n\nNow, you should see a cross-shaped configuration:\n\n### 3. Folding the Faces to Craft the Cube\n\nOur next step involves folding the faces to create the cube effect. This entails utilizing `rotateX()`, `rotateY()` and specifying the vertex from which the folding originates via `transform-origin`.\n\nFor the **back face** we need to adjust the `transform-origin` both the Y and Z axes since it is located two faces away from the front face.\n\n```css\n.face.front {\n}\n\n.face.bottom {\n  top: 100%;\n  transform-origin: top;\n  transform: rotateX(-90deg);\n}\n\n.face.top {\n  bottom: 100%;\n  transform-origin: bottom;\n  transform: rotateX(90deg);\n}\n\n.face.back {\n  bottom: 200%;\n  transform-origin: center 150px -50px;\n  transform: rotateX(180deg);\n}\n\n.face.right {\n  left: 100%;\n  transform-origin: left;\n  transform: rotateY(90deg);\n}\n\n.face.left {\n  right: 100%;\n  transform-origin: right;\n  transform: rotateY(-90deg);\n}\n```\n\n### 4. Applying Shading to the Faces\n\nTo achieve a convincing 3D effect, we need to introduce shading to the faces. Although CSS lacks native lighting, we can create the illusion of depth by varying the lightness of colors.\n\nWe'll utilize the `lightness` property of `hsl()` to produce distinct shades for each face.\n\n```css\n.face {\n  background-color: hsl(39, 100%, var(--lightness));\n}\n\n.face.front {\n  --lightness: 66%;\n}\n\n.face.bottom {\n  --lightness: 74%;\n}\n\n.face.top {\n  --lightness: 74%;\n}\n\n.face.back {\n  --lightness: 78%;\n}\n\n.face.right {\n  --lightness: 70%;\n}\n\n.face.left {\n  --lightness: 70%;\n}\n```\n\nNow, you should behold a splendid 3D cube, crafted solely with HTML and CSS!\n\n---\n\nI hope this tutorial has ignited your imagination for creating captivating 3D animations with pure HTML and CSS.\n\nFeel free to share your creations in the comments section!\nAnd for more content like this, be sure to follow me [@PaucotMartin](https://twitter.com/PaucotMartin) on X (formerly Twitter).\n"}, {"info":{"path":"upnp-protocol.mdx","absolutePath":"/home/mpaucot/workspace/blog/content/blog/upnp-protocol.mdx"},"lastModified":"2025-05-08T18:13:22.000Z","data":{"title":"UPnP: The art of connecting devices","description":"Learn how to create 3D animations by using only HTML and CSS.","type":"article","date":"2023-09-08T00:00:00.000Z"},"content":"\nSo you built a shiny new mobile app and you want it to chat with your smart camera. Nice! You slap in the camera’s IP address and boom — it works.\n\n**Until… it doesn’t.** One day you restart your router, and suddenly it's like:\n\n> “Who even are you? I don’t know you anymore.”\n\nAnd if you’ve got multiple cameras? It’s chaos. Like trying to find Waldo in a sea of IP addresses.\n\nSo how do the pros do it? How does your app find smart devices automagically, no matter what?\n\n**🎉 Welcome to the wonderful world of UPnP!** — aka “plug me in and let me party on the network.”\n\nIt’s a protocol used in almost all smart home gear (Philips Hue, Google Nest, the fancy fridge that tweets when the milk’s gone bad… you name it). Let’s dive in — no scary technical stuff, promise!\n\n## 🧠 UPnP in a nutshell: \"I'm here!!\"\n\nWhen a smart device joins a network, it yells out:\n\n```\n“Hey everyone! I’m a smart lightbulb!”\n“Here’s my IP: 192.168.1.12 💅”\n“My unique ID is 56a5c464-24eb-485a-8825-920a5a6a0e0f — don’t wear it out.”\n“I’m version 1.12 ✨”\n“My API lives on port 3200 — come visit!”\n```\n\nAnd just like that, every other device on the network knows how to talk to it. No drama, no manual config.\n\n## Let’s build a (not-so-bright) smart bulb\n\nWe’ll play with Node.js and a little library called [node-ssdp](https://www.npmjs.com/package/node-ssdp).\n\n### 💡 The Smart Lightbulb (aka “the fake server”)\n\nLet's write the code that will be living in your Smart Lightbulb.\nIt is a simple HTTP server with a `/toggle` endpoint that can be called to turn the light on or off.\n\n<Callout type=\"warn\">\n\nPlease, don't use Node.js in low-power devices like lightbulbs. Please, don't.\n\n</Callout>\n\n```ts\nimport express from \"express\";\n\nconst port = 3200;\nconst app = express();\n\n// Toggle the bulb (or pretend to)\napp.post(\"/toggle\", (req, res) => {\n  toggleTheLight();\n  res.send(\"Toggled!\");\n});\n\napp.listen(port);\n```\n\nThen we want to start the UPnP server that can broadcast our lightbulb precense to the network.\n\n```ts\nimport { Server } from \"node-ssdp\";\n\nconst server = new Server({\n  udn: \"uuid:56a5c464-24eb-485a-8825-920a5a6a0e0f\",\n});\n\nserver.addUSN(\"urn:schemas-upnp-org:service:bulb:1.12\");\n```\n\nThe `UDN` is like the social security number of your Lightbulb. It’s unique to the smart object and will allow other devices to identify it after restarts.\n\nAnd the `USN`? That’s how it tells the world, “Hey, I’m a bulb. A fabulous one. Version 1.12, thank you very much.”\n\n### 📱 The Mobile App\n\nLet's now write the code for our mobile app that can turn on our lightbulb using it's `/toggle` HTTP endpoint.\n\n```ts\nconst devices = [];\n\nfunction toggleTheLight() {\n  for (const device of devices) {\n    axios.post(`http://${device.address}:3200/toggle`);\n  }\n}\n```\n\nWe now need to discover our Lightbulbs on the network to fill our `devices`. We will use the same `node-ssdp` library by instanciating a client.\n\n```ts\nimport { Client } from \"node-ssdp\";\n\nconst client = new Client();\n\nclient.on(\"response\", function (headers, statusCode, rinfo) {\n  devices.push({\n    address: rinfo.address,\n    uuid: headers.USN,\n  });\n});\n\nclient.search(\"urn:schemas-upnp-org:service:bulb:*\");\n```\n\nWhen using `client.search` the app will sends out a search like:\n\n> “Yo, any bulbs around? I’m not picky.”\n\nAnd all the bulbs will shout back. We can then collect their information to interact with them and turn on the light. (Or make a disco.)\n\n## Real-Life Use Case\n\nIf you are interested to discover my work I wrote a case study about my mission for **Lacoste** where I built a [cinema shopping experience](/case-studies/lacoste-showroom).\n\n## Conlusion\n\nAsking your user to manually enter the IP address of their smart devices is like asking them to read the TOS. Ain’t nobody got time for that!\n\nUPnP is the magic sauce that makes smart devices discoverable and easy to connect. It’s like the friendly neighbor who always knows where the party is at.\n"}], "blog", _sourceConfig)
export const caseStudies = _runtimeAsync.doc<typeof _source.caseStudies>([{"info":{"path":"dotfile.mdx","absolutePath":"/home/mpaucot/workspace/blog/content/case-studies/dotfile.mdx"},"lastModified":"2025-05-08T18:13:22.000Z","data":{"title":"Dotfile’s Journey to a Compliant Cloud","description":"Transforming legacy systems into a fortress of trust: a zero‑trust, multi‑account cloud migration delivering elite, certified security.","date":"2025-04-03T00:00:00.000Z","type":"case-study","logo":"/customers/mentorshow.svg"},"content":"\n## Overview\n\nDotfile is a pioneering compliance platform that streamlines business verification and risk management for financial institutions and fintech companies.\n\nThe legacy infrastructure struggled to keep up with the company's rapid growth in term of performance and security.\n\n![Dotfile website](/images/case-studies/dotfile/screenshot-1.png)\n\n## Goals & Challenges\n\nThe primary goal was to transform Dotfile’s cloud infrastructure to better support its growth while significantly boosting security and compliance. Key challenges included:\n\n- **Zero trust Security**:  \n  Establish a robust, zero-trust security model that rigorously verifies every access attempt, ensuring the utmost protection for sensitive data.\n\n- **Scalability and Flexibility:**  \n  Build an infrastructure that can follow the company’s rapid growth trajectory and facilitating Dotfile to meet their SLA commitments.\n\n- **Regulatory Compliance**:  \n  Attain and maintain industry-leading standards, specifically targeting SOC 2 and ISO 27001, to foster trust among clients and stakeholders.\n\n- **Operational Efficiency:**  \n  Implement modern cloud tooling to streamline deployment and maintenance, facilitating agile responses to emerging needs.\n\n## Approach & Technologies\n\n- **Workloads segregation:**  \n  Reduce blast radius and enhance security by isolating workloads into separate AWS accounts, with strict and clear security policies and access controls.\n\n- **Zero-trust architecture:**  \n  Reduce attack surface by implementing a zero-trust architecture with zero public endpoint and strict security policies following industry standards.\n\n- **Forensic Ready:**  \n  Create a forensic-ready infrastructure by implementing comprehensive logging and monitoring solutions, ensuring that all access and actions are recorded and can be audited.\n\n- **Modern Cloud Automation Tools:**  \n  Entirely manage the infrastructure using [Terraform](https://terraform.io), [Terragrunt](https://terragrunt.gruntwork.io/) and [CDKTF](https://developer.hashicorp.com/terraform/cdktf), enabling infrastructure as code and facilitating rapid deployment and scaling.\n\n## Conclusion\n\nDotfile’s journey to a compliant cloud showcases the power of modern cloud engineering.\n\nBy migrating to a multi-account structure with a zero‑trust architecture and strict workload isolation, Dotfile fortified its security and achieved forensic readiness.\n\nLeveraging Terraform, Terragrunt, and CDKTF for infrastructure as code enabled rapid, scalable deployments while meeting SOC 2 and ISO 27001 requirements.\n\nThis transformation not only protects sensitive data but also empowers Dotfile to support rapid growth and drive future innovation.\n"}, {"info":{"path":"franprix-venue.mdx","absolutePath":"/home/mpaucot/workspace/blog/content/case-studies/franprix-venue.mdx"},"lastModified":"2025-05-08T18:13:22.000Z","data":{"title":"Offline-First Infrastructure for Franprix Venue","description":"Redefining event infrastructure with a high-availability, on-site platform powering hundreds of devices without relying on the internet","date":"2024-04-03T00:00:00.000Z","type":"case-study"},"content":"\n## Overview\n\nFranprix hosts an annual salon bringing together franchise store directors and major brand partners. During the event, hundreds of tablets are distributed to attendees, enabling them to place product orders directly with suppliers in real time.\n\nHowever, the venue’s unreliable internet connection posed a critical risk to the event’s success. Ensuring a flawless, always-on experience without relying on external connectivity became a central challenge.\n\n![/images/case-studies/franprix/salon.webp](/images/case-studies/franprix/salon.webp)\n\n## Goals & Challenges\n\nThe main objective was to provide a seamless, high-availability ordering experience for all participants without depending on the public internet.\n\n- **High Availability:**  \n  Ensure that the ordering system remains operational during the entire event.\n\n- **Offline-First:**  \n  Build a system that can function without internet access, allowing users to place orders even in the event of connectivity issues.\n\n- **Monitoring and Support:**  \n  Implement a robust monitoring system to track the performance of the infrastructure and provide real-time support during the event.\n\n## Approach & Technologies\n\n- **High availability:**  \n  The on-premise infrastructure has been built on multiple servers managed in cluster using [Proxmox](https://www.proxmox.com/) to ensure high availability and redundancy even in the event of hardware failure.\n\n- **Private Network:**  \n  The services has been made accessible through a private network, ensuring that all devices can communicate with the ordering system without relying on public internet.\n\n- **Monitoring solution:**  \n  Monitoring dashboards has been provided to Franprix engineers to track the performance of the infrastructure and allowing them to deploy fixes in real time.\n\n- **On-site Support:**  \n  Providing on-site support during the event to ensure that any issues could be quickly identified and resolved.\n\n## Conclusion\n\nBy designing and deploying a fully independent, bare-metal infrastructure, I empowered Franprix to deliver a seamless ordering experience at their annual salon — without a single point of failure.\n\nThis project reflects the strength of tailored infrastructure solutions — engineered for resilience, delivered with precision.\n"}, {"info":{"path":"lacoste-showroom.mdx","absolutePath":"/home/mpaucot/workspace/blog/content/case-studies/lacoste-showroom.mdx"},"lastModified":"2025-05-08T18:13:22.000Z","data":{"title":"Phygitalise Lacoste Showroooms","description":"Building a cinema shopping experience for Lacoste Showrooms.","date":"2024-04-03T00:00:00.000Z","type":"case-study"},"content":"\nLacoste, the iconic French fashion brand, wanted to enhance its showroom experience through digital innovation.\n\nThe goal was to create a \"phygital\" environment where sales representatives could deliver immersive presentations and clients could browse and purchase items using large interactive tablets connected to giant displays.\n\n![Lacoste Showroom Picture](/images/case-studies/lacoste/showcase.webp)\n\n## Goals & Challenges\n\n- **Worldwide deployment:**  \n  The application needed to be deployed in showrooms across the globe, including Paris, New York, and Tokyo.\n\n- **Ease of use:**  \n  The implementation must be simple enough for sales teams to use without extensive training.\n\n- **Security Compliance:**  \n  The application must comply with Lacoste's strict security policies.\n\n- **Scalability and flexibility:**  \n  The solution should be scalable to accommodate future growth and changes.\n\n## Approach & Technologies\n\n- **IoT tehnologies:**  \n  Implementation of the [uPnP protocol](/blog/upnpn-protocol) to simplify installation in private and secure networks.\n\n- **Auto-update mechanism:**  \n  Provided a seamless update process to allow instant deployment on all showrooms across the world without disrupting the user experience .\n\n- **Extensive monitoring:**  \n  Configuration of real-time monitoring solutions to track the application's performance and usage, ensuring that any issues could be quickly identified and resolved.\n\n## Conclusion\n\nLacoste is now able to offer a unique and engaging shopping experience that combines the best of both physical and digital worlds.\n\nThe phygital showroom not only enhances customer engagement but also streamlines the sales process, making it easier for sales representatives to showcase products and for clients to make informed purchasing decisions.\n"}, {"info":{"path":"mentorshow.mdx","absolutePath":"/home/mpaucot/workspace/blog/content/case-studies/mentorshow.mdx"},"lastModified":"2025-05-08T18:13:22.000Z","data":{"title":"MentorShow Platform Rebuild","description":"Reinventing the mentorship experience through a modern and scalable technology stack","date":"2025-04-03T00:00:00.000Z","type":"case-study","logo":"/customers/mentorshow.svg"},"content":"\n## Overview\n\nMentorShow is a dynamic online masterclass platform offering exclusive courses from renowned experts.\n\nThe legacy platform delivered inconsistent user experiences and hampered the rollout of new features, making it difficult to support rapid expansion. With plans to enter new international markets, the platform needed a complete rebuild to ensure a unified, high-performance experience across all devices.\n\n<Gallery>\n\n![Screenshot 1](/images/case-studies/mentorshow/screenshot-1.png)\n![Screenshot 2](/images/case-studies/mentorshow/screenshot-2.png)\n![Screenshot 3](/images/case-studies/mentorshow/screenshot-3.png)\n![Screenshot 4](/images/case-studies/mentorshow/screenshot-4.png)\n\n</Gallery>\n\n## Goals & Challenges\n\n- **Unified experience:**  \n  Consolidate the user journey and eliminate inconsistencies across devices.\n\n- **Scalability & Global expansion:**  \n  Build a platform that can handle rapid growth and support new features without compromising performance.\n\n## Approach and Technologies\n\nTo achieve these goals, we adopted a modern technology stack and a user-centric design approach.\nThe new platform was built from the ground up, focusing on performance, scalability, and user experience.\n\n- **Backend:**  \n  Built with [Adonis.JS](https://adonisjs.com/) to create a robust and scalable [OpenAPI Complient API](https://www.openapis.org/), ensuring seamless integration with the frontend.\n\n- **Marketing website:**  \n  Built with [Next.js](https://nextjs.org/) to provide a fast and responsive experience for users, with a focus on SEO and performance.\n\n- **Web and Mobile apps:**  \n  Built with [Expo](https://expo.dev/) to deliver a consistent experience across all devices, with a focus on performance and user experience.\n\n- **Infrastructure and Hosting:**  \n  [Vercel](https://vercel.com/) for the marketing website and the web app, and [Kubernetes](https://kubernetes.io/) on [AWS](https://aws.amazon.com/) for the backend, ensuring scalability and reliability.\n\n## Conclusion\n\nThe MentorShow platform rebuild successfully addressed legacy challenges by unifying mobile and web experiences and modernizing the technical foundation.\n\nMentorShow successfully launched in new international markets, with a scalable platform that supports rapid growth and feature development.\n"}], "caseStudies", _sourceConfig)